# netdata configuration
#
# You can download the latest version of this file, using:
#
#  wget -O /etc/netdata/netdata.conf http://localhost:19999/netdata.conf
# or
#  curl -o /etc/netdata/netdata.conf http://localhost:19999/netdata.conf
#
# You can uncomment and change any of the options below.
# The value shown in the commented settings, is the default value.
#

# global netdata configuration

[global]
	# run as user = root
	# host access prefix = /host
	# glibc malloc arena max for plugins = 1
	# glibc malloc arena max for netdata = 1
	# hostname = b17913f8d0b3
	# history = 3996
	# update every = 1
	# config directory = /etc/netdata
	# log directory = /var/log/netdata
	# web files directory = /usr/share/netdata/web
	# cache directory = /var/cache/netdata
	# lib directory = /var/lib/netdata
	# home directory = /var/cache/netdata
	# plugins directory = "/usr/libexec/netdata/plugins.d" "/etc/netdata/custom-plugins.d"
	# memory mode = save
	# memory deduplication (ksm) = yes
	# TZ environment variable = :/etc/localtime
	# timezone = Etc/UTC
	# debug flags = 0x0000000000000000
	# debug log = /var/log/netdata/debug.log
	# error log = /var/log/netdata/error.log
	# access log = /var/log/netdata/access.log
	# errors flood protection period = 1200
	# errors to trigger flood protection = 200
	# OOM score = 1000
	# process scheduling policy = idle
	# pthread stack size = 8388608
	# cleanup obsolete charts after seconds = 3600
	# gap when lost iterations above = 1
	# cleanup orphan hosts after seconds = 3600
	# delete obsolete charts files = yes
	# delete orphan hosts files = yes

[web]
	# default port = 19999
	# mode = static-threaded
	# listen backlog = 4096
	# bind to = *
	# web files owner = root
	# web files group = root
	# disconnect idle clients after seconds = 60
	# timeout for first request = 60
	# respect do not track policy = no
	# x-frame-options response header = 
	# allow connections from = localhost *
	# allow dashboard from = localhost *
	# allow badges from = *
	# allow streaming from = *
	# allow netdata.conf from = localhost fd* 10.* 192.168.* 172.16.* 172.17.* 172.18.* 172.19.* 172.20.* 172.21.* 172.22.* 172.23.* 172.24.* 172.25.* 172.26.* 172.27.* 172.28.* 172.29.* 172.30.* 172.31.*
	# enable gzip compression = yes
	# gzip compression strategy = default
	# gzip compression level = 3
	# web server threads = 1
	# web server max sockets = 32768

[plugins]
	# PATH environment variable = /usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/sbin:/usr/sbin:/usr/local/bin:/usr/local/sbin
	# PYTHONPATH environment variable = 
	# proc = yes
	# diskspace = yes
	# cgroups = yes
	# tc = yes
	# idlejitter = yes
	# enable running new plugins = yes
	# check for new plugins every = 60
	# apps = yes
	# charts.d = yes
	# fping = yes
	# node.d = yes
	# python.d = yes

[health]
	# enabled = yes
	# in memory max health log entries = 1000
	# script to execute on alarm = /usr/libexec/netdata/plugins.d/alarm-notify.sh
	# health configuration directory = /etc/netdata/health.d
	# run at least every seconds = 10
	# postpone alarms during hibernation for seconds = 60
	# rotate log every lines = 2000

[registry]
	# enabled = no
	# registry db directory = /var/lib/netdata/registry
	# netdata unique id file = /var/lib/netdata/registry/netdata.public.unique.id
	# registry db file = /var/lib/netdata/registry/registry.db
	# registry log file = /var/lib/netdata/registry/registry-log.db
	# registry save db every new entries = 1000000
	# registry expire idle persons days = 365
	# registry domain = 
	# registry to announce = https://registry.my-netdata.io
	# registry hostname = b17913f8d0b3
	# verify browser cookies support = yes
	# max URL length = 1024
	# max URL name length = 50
	# allow from = *

[backend]
	# host tags = 
	# enabled = no
	# data source = average
	# type = graphite
	# destination = localhost
	# prefix = netdata
	# hostname = b17913f8d0b3
	# update every = 10
	# buffer on failures = 10
	# timeout ms = 20000
	# send names instead of ids = yes
	# send charts matching = *
	# send hosts matching = localhost *

[statsd]
	# enabled = yes
	# update every (flushInterval) = 1
	# udp messages to process at once = 10
	# create private charts for metrics matching = *
	# max private charts allowed = 200
	# max private charts hard limit = 1000
	# private charts memory mode = save
	# private charts history = 3996
	# decimal detail = 1000
	# disconnect idle tcp clients after seconds = 600
	# private charts hidden = no
	# histograms and timers percentile (percentThreshold) = 95.00000
	# add dimension for number of events received = yes
	# gaps on gauges (deleteGauges) = no
	# gaps on counters (deleteCounters) = no
	# gaps on meters (deleteMeters) = no
	# gaps on sets (deleteSets) = no
	# gaps on histograms (deleteHistograms) = no
	# gaps on timers (deleteTimers) = no
	# statsd server max TCP sockets = 16384
	# listen backlog = 4096
	# default port = 8125
	# bind to = udp:localhost tcp:localhost


# per plugin configuration

[plugin:apps]
	# update every = 1
	# command options = 

[plugin:charts.d]
	# update every = 1
	# command options = 

[plugin:fping]
	# update every = 1
	# command options = 

[plugin:node.d]
	# update every = 1
	# command options = 

[plugin:cgroups]
	# cgroups plugin resource charts = yes
	# update every = 1
	# check for new cgroups every = 10
	# enable cpuacct stat (total CPU) = auto
	# enable cpuacct usage (per core CPU) = auto
	# enable memory (used mem including cache) = auto
	# enable detailed memory = auto
	# enable memory limits fail count = auto
	# enable swap memory = auto
	# enable blkio bandwidth = auto
	# enable blkio operations = auto
	# enable blkio throttle bandwidth = auto
	# enable blkio throttle operations = auto
	# enable blkio queued operations = auto
	# enable blkio merged operations = auto
	# recheck zero blkio every iterations = 10
	# recheck zero memory failcnt every iterations = 10
	# recheck zero detailed memory every iterations = 10
	# enable systemd services = yes
	# enable systemd services detailed memory = no
	# report used memory without cache = yes
	# path to /sys/fs/cgroup/cpuacct = /host/sys/fs/cgroup/cpuacct
	# path to /sys/fs/cgroup/blkio = /host/sys/fs/cgroup/blkio
	# path to /sys/fs/cgroup/memory = /host/sys/fs/cgroup/memory
	# path to /sys/fs/cgroup/devices = /host/sys/fs/cgroup/devices
	# max cgroups to allow = 1000
	# max cgroups depth to monitor = 0
	# enable new cgroups detected at run time = yes
	# enable by default cgroups matching =  !*/init.scope  !/system.slice/run-*.scope  *.scope  /machine.slice/*.service  !*/vcpu*  !*/emulator  !*.mount  !*.partition  !*.service  !*.socket  !*.slice  !*.swap  !*.user  !/  !/docker  !/libvirt  !/lxc  !/lxc/*/*  !/machine  !/qemu  !/system  !/systemd  !/user  * 
	# search for cgroups in subpaths matching =  !*/init.scope  !*-qemu  !*.libvirt-qemu  !/init.scope  !/system  !/systemd  !/user  !/user.slice  !/lxc/*/*  * 
	# script to get cgroup names = /usr/libexec/netdata/plugins.d/cgroup-name.sh
	# script to get cgroup network interfaces = /usr/libexec/netdata/plugins.d/cgroup-network
	# run script to rename cgroups matching =  !/  !*.mount  !*.socket  !*.partition  /machine.slice/*.service  !*.service  !*.slice  !*.swap  !*.user  !init.scope  !*.scope/vcpu*  !*.scope/emulator  *.scope  *docker*  *lxc*  *qemu*  *kubepods*  *.libvirt-qemu  * 
	# cgroups to match as systemd services =  !/system.slice/*/*.service  /system.slice/*.service 

[plugin:proc]
	# netdata server resources = yes
	# /proc/stat = yes
	# /proc/uptime = yes
	# /proc/loadavg = yes
	# /proc/sys/kernel/random/entropy_avail = yes
	# /proc/interrupts = yes
	# /proc/softirqs = yes
	# /proc/vmstat = yes
	# /proc/meminfo = yes
	# /sys/kernel/mm/ksm = yes
	# /sys/devices/system/edac/mc = yes
	# /sys/devices/system/node = yes
	# /proc/net/dev = yes
	# /proc/net/sockstat = yes
	# /proc/net/sockstat6 = yes
	# /proc/net/netstat = yes
	# /proc/net/snmp = yes
	# /proc/net/snmp6 = yes
	# /proc/net/softnet_stat = yes
	# /proc/net/ip_vs/stats = yes
	# /proc/net/stat/conntrack = yes
	# /proc/net/stat/synproxy = yes
	/proc/diskstats = no
	# /proc/net/rpc/nfsd = yes
	# /proc/net/rpc/nfs = yes
	# /proc/spl/kstat/zfs/arcstats = yes
	# /sys/fs/btrfs = yes
	# ipc = yes

[plugin:proc:diskspace]
	# remove charts of unmounted disks = yes
	# update every = 1
	# check for new mount points every = 15

[plugin:idlejitter]
	# loop time in ms = 20

[plugin:python.d]
	# update every = 1
	# command options = 

[plugin:tc]
	# script to run to get tc values = /usr/libexec/netdata/plugins.d/tc-qos-helper.sh

[plugin:proc:/proc/stat]
	# cpu utilization = yes
	# per cpu core utilization = yes
	# cpu interrupts = yes
	# context switches = yes
	# processes started = yes
	# processes running = yes
	# keep per core files open = yes
	# core_throttle_count = auto
	# package_throttle_count = no
	# scaling_cur_freq = no
	# core_throttle_count filename to monitor = /host/sys/devices/system/cpu/%s/thermal_throttle/core_throttle_count
	# package_throttle_count filename to monitor = /host/sys/devices/system/cpu/%s/thermal_throttle/package_throttle_count
	# scaling_cur_freq filename to monitor = /host/sys/devices/system/cpu/%s/cpufreq/scaling_cur_freq
	# filename to monitor = /host/proc/stat

[plugin:proc:/proc/uptime]
	# filename to monitor = /host/proc/uptime

[plugin:proc:/proc/loadavg]
	# filename to monitor = /host/proc/loadavg

[plugin:proc:/proc/sys/kernel/random/entropy_avail]
	# filename to monitor = /host/proc/sys/kernel/random/entropy_avail

[plugin:proc:/proc/interrupts]
	# interrupts per core = yes
	# filename to monitor = /host/proc/interrupts

[plugin:proc:/proc/softirqs]
	# interrupts per core = yes
	# filename to monitor = /host/proc/softirqs

[plugin:proc:/proc/vmstat]
	# swap i/o = auto
	# disk i/o = yes
	# memory page faults = yes
	# system-wide numa metric summary = auto
	# filename to monitor = /host/proc/vmstat

[plugin:proc:/sys/devices/system/node]
	# directory to monitor = /host/sys/devices/system/node

[plugin:proc:/proc/meminfo]
	# system ram = yes
	# system swap = auto
	# hardware corrupted ECC = auto
	# committed memory = yes
	# writeback memory = yes
	# kernel memory = yes
	# slab memory = yes
	# hugepages = auto
	# transparent hugepages = auto
	# filename to monitor = /host/proc/meminfo

[plugin:proc:/sys/kernel/mm/ksm]
	# /sys/kernel/mm/ksm/pages_shared = /host/sys/kernel/mm/ksm/pages_shared
	# /sys/kernel/mm/ksm/pages_sharing = /host/sys/kernel/mm/ksm/pages_sharing
	# /sys/kernel/mm/ksm/pages_unshared = /host/sys/kernel/mm/ksm/pages_unshared
	# /sys/kernel/mm/ksm/pages_volatile = /host/sys/kernel/mm/ksm/pages_volatile

[plugin:proc:/sys/devices/system/edac/mc]
	# directory to monitor = /host/sys/devices/system/edac/mc

[plugin:proc:/proc/net/dev]
	# path to get virtual interfaces = /host/sys/devices/virtual/net/%s
	# enable new interfaces detected at runtime = auto
	# bandwidth for all interfaces = auto
	# packets for all interfaces = auto
	# errors for all interfaces = auto
	# drops for all interfaces = auto
	# fifo for all interfaces = auto
	# compressed packets for all interfaces = auto
	# frames, collisions, carrier counters for all interfaces = auto
	# disable by default interfaces matching = lo fireqos* *-ifb
	# filename to monitor = /host/proc/net/dev

[plugin:proc:/proc/net/sockstat]
	# ipv4 sockets = auto
	# ipv4 TCP sockets = auto
	# ipv4 TCP memory = auto
	# ipv4 UDP sockets = auto
	# ipv4 UDP memory = auto
	# ipv4 UDPLITE sockets = auto
	# ipv4 RAW sockets = auto
	# ipv4 FRAG sockets = auto
	# ipv4 FRAG memory = auto
	# update constants every = 60
	# filename to monitor = /host/proc/net/sockstat

[plugin:proc:/proc/net/sockstat6]
	# ipv6 TCP sockets = auto
	# ipv6 UDP sockets = auto
	# ipv6 UDPLITE sockets = auto
	# ipv6 RAW sockets = auto
	# ipv6 FRAG sockets = auto
	# filename to monitor = /host/proc/net/sockstat6

[plugin:proc:/proc/net/netstat]
	# bandwidth = auto
	# input errors = auto
	# multicast bandwidth = auto
	# broadcast bandwidth = auto
	# multicast packets = auto
	# broadcast packets = auto
	# ECN packets = auto
	# TCP reorders = auto
	# TCP SYN cookies = auto
	# TCP out-of-order queue = auto
	# TCP connection aborts = auto
	# TCP memory pressures = auto
	# TCP listen issues = auto
	# filename to monitor = /host/proc/net/netstat

[plugin:proc:/proc/net/snmp]
	# ipv4 packets = yes
	# ipv4 fragments sent = yes
	# ipv4 fragments assembly = yes
	# ipv4 errors = yes
	# ipv4 TCP connections = yes
	# ipv4 TCP packets = yes
	# ipv4 TCP errors = yes
	# ipv4 TCP opens = yes
	# ipv4 TCP handshake issues = yes
	# ipv4 UDP packets = yes
	# ipv4 UDP errors = yes
	# ipv4 ICMP packets = yes
	# ipv4 ICMP messages = yes
	# ipv4 UDPLite packets = yes
	# filename to monitor = /host/proc/net/snmp

[plugin:proc:/proc/net/snmp6]
	# ipv6 packets = auto
	# ipv6 fragments sent = auto
	# ipv6 fragments assembly = auto
	# ipv6 errors = auto
	# ipv6 UDP packets = auto
	# ipv6 UDP errors = auto
	# ipv6 UDPlite packets = auto
	# ipv6 UDPlite errors = auto
	# bandwidth = auto
	# multicast bandwidth = auto
	# broadcast bandwidth = auto
	# multicast packets = auto
	# icmp = auto
	# icmp redirects = auto
	# icmp errors = auto
	# icmp echos = auto
	# icmp group membership = auto
	# icmp router = auto
	# icmp neighbor = auto
	# icmp mldv2 = auto
	# icmp types = auto
	# ect = auto
	# filename to monitor = /host/proc/net/snmp6

[plugin:proc:/proc/net/softnet_stat]
	# softnet_stat per core = yes
	# filename to monitor = /host/proc/net/softnet_stat

[plugin:proc:/proc/net/ip_vs_stats]
	# IPVS bandwidth = yes
	# IPVS connections = yes
	# IPVS packets = yes
	# filename to monitor = /host/proc/net/ip_vs_stats

[plugin:proc:/proc/net/stat/nf_conntrack]
	# filename to monitor = /host/proc/net/stat/nf_conntrack
	# netfilter new connections = no
	# netfilter connection changes = no
	# netfilter connection expectations = no
	# netfilter connection searches = no
	# netfilter errors = no
	# netfilter connections = no

[plugin:proc:/proc/sys/net/netfilter/nf_conntrack_max]
	# filename to monitor = /host/proc/sys/net/netfilter/nf_conntrack_max
	# read every seconds = 10

[plugin:proc:/proc/sys/net/netfilter/nf_conntrack_count]
	# filename to monitor = /host/proc/sys/net/netfilter/nf_conntrack_count

[plugin:proc:/proc/net/stat/synproxy]
	# SYNPROXY entries = auto
	# SYNPROXY cookies = auto
	# SYNPROXY SYN received = auto
	# SYNPROXY connections reopened = auto
	# filename to monitor = /host/proc/net/stat/synproxy

[plugin:proc:/proc/diskstats]
	# enable new disks detected at runtime = yes
	# performance metrics for physical disks = auto
	# performance metrics for virtual disks = auto
	# performance metrics for partitions = no
	# bandwidth for all disks = auto
	# operations for all disks = auto
	# merged operations for all disks = auto
	# i/o time for all disks = auto
	# queued operations for all disks = auto
	# utilization percentage for all disks = auto
	# backlog for all disks = auto
	# bcache for all disks = auto
	# remove charts of removed disks = yes
	# path to get block device = /host/sys/block/%s
	# path to get block device bcache = /host/sys/block/%s/bcache
	# path to get virtual block device = /host/sys/devices/virtual/block/%s
	# path to get block device infos = /host/sys/dev/block/%lu:%lu/%s
	# path to device mapper = /host/dev/mapper
	# path to /dev/disk/by-label = /host/dev/disk/by-label
	# path to /dev/disk/by-id = /host/dev/disk/by-id
	# name disks by id = no
	# exclude disks = loop* ram*
	# filename to monitor = /host/proc/diskstats

[plugin:proc:/proc/net/rpc/nfsd]
	# filename to monitor = /host/proc/net/rpc/nfsd

[plugin:proc:/proc/net/rpc/nfs]
	# filename to monitor = /host/proc/net/rpc/nfs

[plugin:proc:/proc/spl/kstat/zfs/arcstats]
	# filename to monitor = /host/proc/spl/kstat/zfs/arcstats

[plugin:proc:/sys/fs/btrfs]
	# path to monitor = /host/sys/fs/btrfs
	# check for btrfs changes every = 60
	# physical disks allocation = auto
	# data allocation = auto
	# metadata allocation = auto
	# system allocation = auto


# per chart configuration

[system.idlejitter]
	# history = 3996
	# enabled = yes
	# cache directory = /var/cache/netdata/system.idlejitter
	# chart type = area
	# type = system
	# family = idlejitter
	# units = microseconds lost/s
	# context = system.idlejitter
	# priority = 800
	# name = system.idlejitter
	# title = CPU Idle Jitter
	# dim min name = min
	# dim min algorithm = absolute
	# dim min multiplier = 1
	# dim min divisor = 1
	# dim max name = max
	# dim max algorithm = absolute
	# dim max multiplier = 1
	# dim max divisor = 1
	# dim average name = average
	# dim average algorithm = absolute
	# dim average multiplier = 1
	# dim average divisor = 1

[netdata.statsd_metrics]
	# history = 3996
	# enabled = yes
	# cache directory = /var/cache/netdata/netdata.statsd_metrics
	# chart type = stacked
	# type = netdata
	# family = statsd
	# units = metrics
	# context = netdata.statsd_metrics
	# priority = 132010
	# name = netdata.statsd_metrics
	# title = Metrics in the netdata statsd database
	# dim gauges name = gauges
	# dim gauges algorithm = absolute
	# dim gauges multiplier = 1
	# dim gauges divisor = 1
	# dim counters name = counters
	# dim counters algorithm = absolute
	# dim counters multiplier = 1
	# dim counters divisor = 1
	# dim timers name = timers
	# dim timers algorithm = absolute
	# dim timers multiplier = 1
	# dim timers divisor = 1
	# dim meters name = meters
	# dim meters algorithm = absolute
	# dim meters multiplier = 1
	# dim meters divisor = 1
	# dim histograms name = histograms
	# dim histograms algorithm = absolute
	# dim histograms multiplier = 1
	# dim histograms divisor = 1
	# dim sets name = sets
	# dim sets algorithm = absolute
	# dim sets multiplier = 1
	# dim sets divisor = 1

[netdata.statsd_events]
	# history = 3996
	# enabled = yes
	# cache directory = /var/cache/netdata/netdata.statsd_events
	# chart type = stacked
	# type = netdata
	# family = statsd
	# units = events/s
	# context = netdata.statsd_events
	# priority = 132011
	# name = netdata.statsd_events
	# title = Events processed by the netdata statsd server
	# dim gauges name = gauges
	# dim gauges algorithm = incremental
	# dim gauges multiplier = 1
	# dim gauges divisor = 1
	# dim counters name = counters
	# dim counters algorithm = incremental
	# dim counters multiplier = 1
	# dim counters divisor = 1
	# dim timers name = timers
	# dim timers algorithm = incremental
	# dim timers multiplier = 1
	# dim timers divisor = 1
	# dim meters name = meters
	# dim meters algorithm = incremental
	# dim meters multiplier = 1
	# dim meters divisor = 1
	# dim histograms name = histograms
	# dim histograms algorithm = incremental
	# dim histograms multiplier = 1
	# dim histograms divisor = 1
	# dim sets name = sets
	# dim sets algorithm = incremental
	# dim sets multiplier = 1
	# dim sets divisor = 1
	# dim unknown name = unknown
	# dim unknown algorithm = incremental
	# dim unknown multiplier = 1
	# dim unknown divisor = 1
	# dim errors name = errors
	# dim errors algorithm = incremental
	# dim errors multiplier = 1
	# dim errors divisor = 1

[netdata.statsd_reads]
	# history = 3996
	# enabled = yes
	# cache directory = /var/cache/netdata/netdata.statsd_reads
	# chart type = stacked
	# type = netdata
	# family = statsd
	# units = reads/s
	# context = netdata.statsd_reads
	# priority = 132012
	# name = netdata.statsd_reads
	# title = Read operations made by the netdata statsd server
	# dim tcp name = tcp
	# dim tcp algorithm = incremental
	# dim tcp multiplier = 1
	# dim tcp divisor = 1
	# dim udp name = udp
	# dim udp algorithm = incremental
	# dim udp multiplier = 1
	# dim udp divisor = 1

[netdata.statsd_bytes]
	# history = 3996
	# enabled = yes
	# cache directory = /var/cache/netdata/netdata.statsd_bytes
	# chart type = stacked
	# type = netdata
	# family = statsd
	# units = kilobits/s
	# context = netdata.statsd_bytes
	# priority = 132013
	# name = netdata.statsd_bytes
	# title = Bytes read by the netdata statsd server
	# dim tcp name = tcp
	# dim tcp algorithm = incremental
	# dim tcp multiplier = 8
	# dim tcp divisor = 1000
	# dim udp name = udp
	# dim udp algorithm = incremental
	# dim udp multiplier = 8
	# dim udp divisor = 1000

[netdata.statsd_packets]
	# history = 3996
	# enabled = yes
	# cache directory = /var/cache/netdata/netdata.statsd_packets
	# chart type = stacked
	# type = netdata
	# family = statsd
	# units = packets/s
	# context = netdata.statsd_packets
	# priority = 132014
	# name = netdata.statsd_packets
	# title = Network packets processed by the netdata statsd server
	# dim tcp name = tcp
	# dim tcp algorithm = incremental
	# dim tcp multiplier = 1
	# dim tcp divisor = 1
	# dim udp name = udp
	# dim udp algorithm = incremental
	# dim udp multiplier = 1
	# dim udp divisor = 1

[netdata.tcp_connects]
	# history = 3996
	# enabled = yes
	# cache directory = /var/cache/netdata/netdata.tcp_connects
	# chart type = line
	# type = netdata
	# family = statsd
	# units = events
	# context = netdata.tcp_connects
	# priority = 132015
	# name = netdata.tcp_connects
	# title = statsd server TCP connects and disconnects
	# dim connects name = connects
	# dim connects algorithm = incremental
	# dim connects multiplier = 1
	# dim connects divisor = 1
	# dim disconnects name = disconnects
	# dim disconnects algorithm = incremental
	# dim disconnects multiplier = -1
	# dim disconnects divisor = 1

[netdata.tcp_connected]
	# history = 3996
	# enabled = yes
	# cache directory = /var/cache/netdata/netdata.tcp_connected
	# chart type = line
	# type = netdata
	# family = statsd
	# units = connected
	# context = netdata.tcp_connected
	# priority = 132016
	# name = netdata.tcp_connected
	# title = statsd server TCP connected sockets
	# dim connected name = connected
	# dim connected algorithm = absolute
	# dim connected multiplier = 1
	# dim connected divisor = 1

[netdata.private_charts]
	# history = 3996
	# enabled = yes
	# cache directory = /var/cache/netdata/netdata.private_charts
	# chart type = area
	# type = netdata
	# family = statsd
	# units = charts
	# context = netdata.private_charts
	# priority = 132020
	# name = netdata.private_charts
	# title = Private metric charts created by the netdata statsd server
	# dim charts name = charts
	# dim charts algorithm = absolute
	# dim charts multiplier = 1
	# dim charts divisor = 1

[netdata.plugin_statsd_charting_cpu]
	# history = 3996
	# enabled = yes
	# cache directory = /var/cache/netdata/netdata.plugin_statsd_charting_cpu
	# chart type = stacked
	# type = netdata
	# family = statsd
	# units = milliseconds/s
	# context = netdata.statsd_cpu
	# priority = 132001
	# name = netdata.plugin_statsd_charting_cpu
	# title = NetData statsd charting thread CPU usage
	# dim user name = user
	# dim user algorithm = incremental
	# dim user multiplier = 1
	# dim user divisor = 1000
	# dim system name = system
	# dim system algorithm = incremental
	# dim system multiplier = 1
	# dim system divisor = 1000

[netdata.plugin_statsd_collector1_cpu]
	# history = 3996
	# enabled = yes
	# cache directory = /var/cache/netdata/netdata.plugin_statsd_collector1_cpu
	# chart type = stacked
	# type = netdata
	# family = statsd
	# units = milliseconds/s
	# context = netdata.statsd_cpu
	# priority = 132002
	# name = netdata.plugin_statsd_collector1_cpu
	# title = NetData statsd collector thread No 1 CPU usage
	# dim user name = user
	# dim user algorithm = incremental
	# dim user multiplier = 1
	# dim user divisor = 1000
	# dim system name = system
	# dim system algorithm = incremental
	# dim system multiplier = 1
	# dim system divisor = 1000

[netdata.web_thread1_cpu]
	# history = 3996
	# enabled = yes
	# cache directory = /var/cache/netdata/netdata.web_thread1_cpu
	# chart type = stacked
	# type = netdata
	# family = web
	# units = milliseconds/s
	# context = netdata.web_cpu
	# priority = 132000
	# name = netdata.web_thread1_cpu
	# title = NetData web server thread No 1 CPU usage
	# dim user name = user
	# dim user algorithm = incremental
	# dim user multiplier = 1
	# dim user divisor = 1000
	# dim system name = system
	# dim system algorithm = incremental
	# dim system multiplier = 1
	# dim system divisor = 1000

[netdata.plugin_cgroups_cpu]
	# history = 3996
	# enabled = yes
	# cache directory = /var/cache/netdata/netdata.plugin_cgroups_cpu
	# chart type = stacked
	# type = netdata
	# family = cgroups
	# units = milliseconds/s
	# context = netdata.plugin_cgroups_cpu
	# priority = 132000
	# name = netdata.plugin_cgroups_cpu
	# title = NetData CGroups Plugin CPU usage
	# dim user name = user
	# dim user algorithm = incremental
	# dim user multiplier = 1
	# dim user divisor = 1000
	# dim system name = system
	# dim system algorithm = incremental
	# dim system multiplier = 1
	# dim system divisor = 1000

[netdata.plugin_diskspace]
	# history = 3996
	# enabled = yes
	# cache directory = /var/cache/netdata/netdata.plugin_diskspace
	# chart type = stacked
	# type = netdata
	# family = diskspace
	# units = milliseconds/s
	# context = netdata.plugin_diskspace
	# priority = 132020
	# name = netdata.plugin_diskspace
	# title = NetData Disk Space Plugin CPU usage
	# dim user name = user
	# dim user algorithm = incremental
	# dim user multiplier = 1
	# dim user divisor = 1000
	# dim system name = system
	# dim system algorithm = incremental
	# dim system multiplier = 1
	# dim system divisor = 1000

[system.ipc_semaphores]
	# history = 3996
	# enabled = yes
	# cache directory = /var/cache/netdata/system.ipc_semaphores
	# chart type = area
	# type = system
	# family = ipc semaphores
	# units = semaphores
	# context = system.ipc_semaphores
	# priority = 1000
	# name = system.ipc_semaphores
	# title = IPC Semaphores
	# dim semaphores name = semaphores
	# dim semaphores algorithm = absolute
	# dim semaphores multiplier = 1
	# dim semaphores divisor = 1

[netdata.plugin_diskspace_dt]
	# history = 3996
	# enabled = yes
	# cache directory = /var/cache/netdata/netdata.plugin_diskspace_dt
	# chart type = area
	# type = netdata
	# family = diskspace
	# units = milliseconds/run
	# context = netdata.plugin_diskspace_dt
	# priority = 132021
	# name = netdata.plugin_diskspace_dt
	# title = NetData Disk Space Plugin Duration
	# dim duration name = duration
	# dim duration algorithm = absolute
	# dim duration multiplier = 1
	# dim duration divisor = 1000

[system.ipc_semaphore_arrays]
	# history = 3996
	# enabled = yes
	# cache directory = /var/cache/netdata/system.ipc_semaphore_arrays
	# chart type = area
	# type = system
	# family = ipc semaphores
	# units = arrays
	# context = system.ipc_semaphore_arrays
	# priority = 1000
	# name = system.ipc_semaphore_arrays
	# title = IPC Semaphore Arrays
	# dim arrays name = arrays
	# dim arrays algorithm = absolute
	# dim arrays multiplier = 1
	# dim arrays divisor = 1

[netdata.plugin_proc_modules]
	# history = 3996
	# enabled = yes
	# cache directory = /var/cache/netdata/netdata.plugin_proc_modules
	# chart type = stacked
	# type = netdata
	# family = proc
	# units = milliseconds/run
	# context = netdata.plugin_proc_modules
	# priority = 132001
	# name = netdata.plugin_proc_modules
	# title = NetData Proc Plugin Modules Durations
	# dim diskstats name = diskstats
	# dim diskstats algorithm = absolute
	# dim diskstats multiplier = 1
	# dim diskstats divisor = 1000
	# dim btrfs name = btrfs
	# dim btrfs algorithm = absolute
	# dim btrfs multiplier = 1
	# dim btrfs divisor = 1000
	# dim ipc name = ipc
	# dim ipc algorithm = absolute
	# dim ipc multiplier = 1
	# dim ipc divisor = 1000

[netdata.plugin_proc_cpu]
	# history = 3996
	# enabled = yes
	# cache directory = /var/cache/netdata/netdata.plugin_proc_cpu
	# chart type = stacked
	# type = netdata
	# family = proc
	# units = milliseconds/s
	# context = netdata.plugin_proc_cpu
	# priority = 132000
	# name = netdata.plugin_proc_cpu
	# title = NetData Proc Plugin CPU usage
	# dim user name = user
	# dim user algorithm = incremental
	# dim user multiplier = 1
	# dim user divisor = 1000
	# dim system name = system
	# dim system algorithm = incremental
	# dim system multiplier = 1
	# dim system divisor = 1000

[netdata.server_cpu]
	# history = 3996
	# enabled = yes
	# cache directory = /var/cache/netdata/netdata.server_cpu
	# chart type = stacked
	# type = netdata
	# family = netdata
	# units = milliseconds/s
	# context = netdata.server_cpu
	# priority = 130000
	# name = netdata.server_cpu
	# title = NetData CPU usage
	# dim user name = user
	# dim user algorithm = incremental
	# dim user multiplier = 1
	# dim user divisor = 1000
	# dim system name = system
	# dim system algorithm = incremental
	# dim system multiplier = 1
	# dim system divisor = 1000

[netdata.clients]
	# history = 3996
	# enabled = yes
	# cache directory = /var/cache/netdata/netdata.clients
	# chart type = line
	# type = netdata
	# family = netdata
	# units = connected clients
	# context = netdata.clients
	# priority = 130200
	# name = netdata.clients
	# title = NetData Web Clients
	# dim clients name = clients
	# dim clients algorithm = absolute
	# dim clients multiplier = 1
	# dim clients divisor = 1

[netdata.requests]
	# history = 3996
	# enabled = yes
	# cache directory = /var/cache/netdata/netdata.requests
	# chart type = line
	# type = netdata
	# family = netdata
	# units = requests/s
	# context = netdata.requests
	# priority = 130300
	# name = netdata.requests
	# title = NetData Web Requests
	# dim requests name = requests
	# dim requests algorithm = incremental
	# dim requests multiplier = 1
	# dim requests divisor = 1

[netdata.net]
	# history = 3996
	# enabled = yes
	# cache directory = /var/cache/netdata/netdata.net
	# chart type = area
	# type = netdata
	# family = netdata
	# units = kilobits/s
	# context = netdata.net
	# priority = 130000
	# name = netdata.net
	# title = NetData Network Traffic
	# dim in name = in
	# dim in algorithm = incremental
	# dim in multiplier = 8
	# dim in divisor = 1000
	# dim out name = out
	# dim out algorithm = incremental
	# dim out multiplier = -8
	# dim out divisor = 1000

[netdata.response_time]
	# history = 3996
	# enabled = yes
	# cache directory = /var/cache/netdata/netdata.response_time
	# chart type = line
	# type = netdata
	# family = netdata
	# units = ms/request
	# context = netdata.response_time
	# priority = 130400
	# name = netdata.response_time
	# title = NetData API Response Time
	# dim average name = average
	# dim average algorithm = absolute
	# dim average multiplier = 1
	# dim average divisor = 1000
	# dim max name = max
	# dim max algorithm = absolute
	# dim max multiplier = 1
	# dim max divisor = 1000

[netdata.compression_ratio]
	# history = 3996
	# enabled = yes
	# cache directory = /var/cache/netdata/netdata.compression_ratio
	# chart type = line
	# type = netdata
	# family = netdata
	# units = percentage
	# context = netdata.compression_ratio
	# priority = 130500
	# name = netdata.compression_ratio
	# title = NetData API Responses Compression Savings Ratio
	# dim savings name = savings
	# dim savings algorithm = absolute
	# dim savings multiplier = 1
	# dim savings divisor = 1000

[netdata.plugin_tc_cpu]
	# history = 3996
	# enabled = yes
	# cache directory = /var/cache/netdata/netdata.plugin_tc_cpu
	# chart type = stacked
	# type = netdata
	# family = tc.helper
	# units = milliseconds/s
	# context = netdata.plugin_tc_cpu
	# priority = 135000
	# name = netdata.plugin_tc_cpu
	# title = NetData TC CPU usage
	# dim user name = user
	# dim user algorithm = incremental
	# dim user multiplier = 1
	# dim user divisor = 1000
	# dim system name = system
	# dim system algorithm = incremental
	# dim system multiplier = 1
	# dim system divisor = 1000

[netdata.plugin_tc_time]
	# history = 3996
	# enabled = yes
	# cache directory = /var/cache/netdata/netdata.plugin_tc_time
	# chart type = area
	# type = netdata
	# family = tc.helper
	# units = milliseconds/run
	# context = netdata.plugin_tc_time
	# priority = 135001
	# name = netdata.plugin_tc_time
	# title = NetData TC script execution
	# dim run_time name = run time
	# dim run_time algorithm = absolute
	# dim run_time multiplier = 1
	# dim run_time divisor = 1

[netdata.runtime_cpufreq]
	# history = 3996
	# enabled = yes
	# cache directory = /var/cache/netdata/netdata.runtime_cpufreq
	# chart type = line
	# type = netdata
	# family = python.d
	# units = ms
	# context = netdata.pythond_runtime
	# priority = 145000
	# name = netdata.runtime_cpufreq
	# title = Execution time for cpufreq
	# dim run_time name = run time
	# dim run_time algorithm = absolute
	# dim run_time multiplier = 1
	# dim run_time divisor = 1

[cpu.cpufreq]
	# history = 3996
	# enabled = yes
	# cache directory = /var/cache/netdata/cpu.cpufreq
	# chart type = line
	# type = cpu
	# family = cpufreq
	# units = MHz
	# context = cpufreq.cpufreq
	# priority = 60000
	# name = cpu.cpufreq
	# title = CPU Clock
	# dim cpu0 name = cpu0
	# dim cpu0 algorithm = absolute
	# dim cpu0 multiplier = 1
	# dim cpu0 divisor = 1000
	# dim cpu1 name = cpu1
	# dim cpu1 algorithm = absolute
	# dim cpu1 multiplier = 1
	# dim cpu1 divisor = 1000
	# dim cpu2 name = cpu2
	# dim cpu2 algorithm = absolute
	# dim cpu2 multiplier = 1
	# dim cpu2 divisor = 1000
	# dim cpu3 name = cpu3
	# dim cpu3 algorithm = absolute
	# dim cpu3 multiplier = 1
	# dim cpu3 divisor = 1000
	# dim cpu4 name = cpu4
	# dim cpu4 algorithm = absolute
	# dim cpu4 multiplier = 1
	# dim cpu4 divisor = 1000
	# dim cpu5 name = cpu5
	# dim cpu5 algorithm = absolute
	# dim cpu5 multiplier = 1
	# dim cpu5 divisor = 1000
	# dim cpu6 name = cpu6
	# dim cpu6 algorithm = absolute
	# dim cpu6 multiplier = 1
	# dim cpu6 divisor = 1000
	# dim cpu7 name = cpu7
	# dim cpu7 algorithm = absolute
	# dim cpu7 multiplier = 1
	# dim cpu7 divisor = 1000